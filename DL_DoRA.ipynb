{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1PP8GhTDoxg"
      },
      "source": [
        "## Packages import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2SLtTNCSOgO8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRtlybIfA8bQ",
        "outputId": "ce60812f-0e5b-4740-8b53-9a487dc7c2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in ./.venv/lib/python3.12/site-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%pip install pytesseract pandas scikit-learn transformers json\n",
        "%pip install torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Optional OCR tools\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "# or use EasyOCR:\n",
        "# import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVj1O-69EN49",
        "outputId": "4a5bf68e-07d6-4779-edba-cd515ea2c0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用 Apple M1 GPU (MPS)\n"
          ]
        }
      ],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "\n",
        "# Step 1: 自動選擇 device\n",
        "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"使用 Apple M1 GPU (MPS)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"使用 CPU（找不到 MPS）\")\n",
        "# # Check GPU\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device('mps')\n",
        "#     print(f'使用 GPU：{torch.cuda.get_device_name(0)}')\n",
        "# else:\n",
        "#     device = torch.device('cpu')\n",
        "#     print('使用 CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kztd1CKCXI"
      },
      "source": [
        "## Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "SZcnhYfIESMv",
        "outputId": "a1753eb7-1368-40c1-b911-863bfa1e6aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question Bank Columns: ['subject', 'ques_no', 'chapter_name', 'section_name', 'ques_detl']\n",
            "Chapter List Columns: ['year_grade', 'book', 'chapter_num', 'chapter_name', 'section_num', 'section_name']\n",
            "Question Bank Columns: ['subject', 'ques_no', 'chapter_name', 'section_name', 'ques_detl']\n",
            "Chapter List Columns: ['year_grade', 'book', 'chapter_num', 'chapter_name', 'section_num', 'section_name']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>ques_no</th>\n",
              "      <th>chapter_name_x</th>\n",
              "      <th>section_name</th>\n",
              "      <th>ques_detl</th>\n",
              "      <th>year_grade</th>\n",
              "      <th>book</th>\n",
              "      <th>chapter_num</th>\n",
              "      <th>chapter_name_y</th>\n",
              "      <th>section_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810001</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810002</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\u000b(A)－25　(B...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810003</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\u000b(A)－8　(B...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810004</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810005</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果＋40°表示北緯40°，則南緯30°該如何表示？\u000b(A)30°　(B)－30°  (C)...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject     ques_no chapter_name_x section_name  \\\n",
              "0    math  2MA0810001          整數的運算        負數與數線   \n",
              "1    math  2MA0810002          整數的運算        負數與數線   \n",
              "2    math  2MA0810003          整數的運算        負數與數線   \n",
              "3    math  2MA0810004          整數的運算        負數與數線   \n",
              "4    math  2MA0810005          整數的運算        負數與數線   \n",
              "\n",
              "                                           ques_detl  year_grade  book  \\\n",
              "0  以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...         8.0   1.0   \n",
              "1  若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\n",
              "(A)－25　(B...         8.0   1.0   \n",
              "2  如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\n",
              "(A)－8　(B...         8.0   1.0   \n",
              "3  如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...         8.0   1.0   \n",
              "4  如果＋40°表示北緯40°，則南緯30°該如何表示？\n",
              "(A)30°　(B)－30°  (C)...         8.0   1.0   \n",
              "\n",
              "   chapter_num chapter_name_y  section_num  \n",
              "0          1.0          整數的運算          1.0  \n",
              "1          1.0          整數的運算          1.0  \n",
              "2          1.0          整數的運算          1.0  \n",
              "3          1.0          整數的運算          1.0  \n",
              "4          1.0          整數的運算          1.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_and_merge(subject: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load question bank and chapter list CSVs for a given subject from Database/{subject}_Database and merge on chapter ID.\n",
        "\n",
        "    Args:\n",
        "        subject: 'math' or 'social'\n",
        "    Returns:\n",
        "        DataFrame with columns: question_text, chapter_name, subject\n",
        "    \"\"\"\n",
        "    base_path = f\"Database/{subject}_Database\"\n",
        "    qbank_path = f\"{base_path}/{subject}_question_bank.csv\"\n",
        "    chap_path = f\"{base_path}/{subject}_chapter_list.csv\"\n",
        "    \n",
        "    qdf = pd.read_csv(qbank_path)\n",
        "    cdf = pd.read_csv(chap_path)\n",
        "    qdf.columns = qdf.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "    cdf.columns = cdf.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "    print(\"Question Bank Columns:\", qdf.columns.tolist())\n",
        "    print(\"Chapter List Columns:\", cdf.columns.tolist())\n",
        "\n",
        "\n",
        "    df = qdf.merge(cdf, on='section_name', how='left')\n",
        "    df['subject'] = subject\n",
        "    return df\n",
        "\n",
        "# Load and combine data from correct paths\n",
        "df = pd.concat([load_and_merge('math'), load_and_merge('social')], ignore_index=True)\n",
        "\n",
        "df.count()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C2K-oAKnKlbY",
        "outputId": "5f522948-22c6-44df-f8c7-e30c60ff1d96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>chapter_name_x</th>\n",
              "      <th>section_name</th>\n",
              "      <th>ques_detl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\u000b(A)－25　(B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\u000b(A)－8　(B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果＋40°表示北緯40°，則南緯30°該如何表示？\u000b(A)30°　(B)－30°  (C)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject chapter_name_x section_name  \\\n",
              "0    math          整數的運算        負數與數線   \n",
              "1    math          整數的運算        負數與數線   \n",
              "2    math          整數的運算        負數與數線   \n",
              "3    math          整數的運算        負數與數線   \n",
              "4    math          整數的運算        負數與數線   \n",
              "\n",
              "                                           ques_detl  \n",
              "0  以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...  \n",
              "1  若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\n",
              "(A)－25　(B...  \n",
              "2  如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\n",
              "(A)－8　(B...  \n",
              "3  如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...  \n",
              "4  如果＋40°表示北緯40°，則南緯30°該如何表示？\n",
              "(A)30°　(B)－30°  (C)...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[['subject','chapter_name_x','section_name','ques_detl']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ZMGU1kj-JjuO",
        "outputId": "7c6712f6-2d21-4664-a003-a55d72f32182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subject           33839\n",
              "chapter_name_x    33839\n",
              "section_name      33839\n",
              "ques_detl         33839\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU818S_rJ9-Y",
        "outputId": "f1bfdda4-0286-47e4-eec6-e3493defcc64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33839"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kpzeLe4RKJzZ"
      },
      "outputs": [],
      "source": [
        "# 2. Label Encoding\n",
        "# Combine subject and chapter_name as classification label\n",
        "\n",
        "df['label_str'] = df['subject'] + '::' + df['chapter_name_x']\n",
        "label2id = {lab: i for i, lab in enumerate(sorted(df['label_str'].unique()))}\n",
        "id2label = {i: lab for lab, i in label2id.items()}\n",
        "df['label'] = df['label_str'].map(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_y24qatKGl8",
        "outputId": "a6fe1e40-f33d-421f-80f3-6f3e4043c336"
      },
      "outputs": [],
      "source": [
        "# 3. Train/Test Split\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
        "\n",
        "# 4. Tokenization and Dataset Definition\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class QDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        inputs = self.tokenizer(text,\n",
        "                                 padding='max_length',\n",
        "                                 truncation=True,\n",
        "                                 max_length=self.max_len,\n",
        "                                 return_tensors='pt')\n",
        "        item = {k: v.squeeze() for k, v in inputs.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_dataset = QDataset(train_df['ques_detl'].tolist(), train_df['label'].tolist(), tokenizer)\n",
        "test_dataset = QDataset(test_df['ques_detl'].tolist(), test_df['label'].tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: peft in ./.venv/lib/python3.12/site-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from peft) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from peft) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.12/site-packages (from peft) (2.7.0)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from peft) (4.52.3)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in ./.venv/lib/python3.12/site-packages (from peft) (1.7.0)\n",
            "Requirement already satisfied: safetensors in ./.venv/lib/python3.12/site-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in ./.venv/lib/python3.12/site-packages (from peft) (0.32.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.5.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers->peft) (0.21.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.32.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.5.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,453,095 || all params: 110,965,326 || trainable%: 1.3095\n"
          ]
        }
      ],
      "source": [
        "# LoRA/DoRA 都在 PEFT 裏\n",
        "%pip install -U peft           # >= 0.10 才有 use_dora 參數\n",
        "%pip install -U transformers   # 你本來就有\n",
        "%pip install -U accelerate     # 與 Trainer 配合\n",
        "\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "# 5. Model Initialization\n",
        "\n",
        "# 給 BERT 做分類任務常見的幾個線性層；偷懶也可以 target_modules=\"all-linear\"\n",
        "dora_config = LoraConfig(\n",
        "    r=8,                     # rank；小模型 r=8~16 通常夠用\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",             # 只訓練 LoRA / DoRA 權重\n",
        "    task_type=\"SEQ_CLS\",     # 句子分類\n",
        "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
        "    use_dora=True            # ✨ 關鍵開關\n",
        ")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels= len(label2id)\n",
        ")\n",
        "model = get_peft_model(model, dora_config)\n",
        "model.print_trainable_parameters()  # 檢查只有 DoRA 權重在訓練\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpJoDYM7Lebd",
        "outputId": "d34f857f-3242-4519-cae9-48451c141bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping pytorch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.32.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.5.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/ipykernel_6687/2685679634.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall pytorch  # ← 先移除錯的包\n",
        "%pip install torch --upgrade\n",
        "\n",
        "%pip install -U accelerate\n",
        "%pip install -U transformers\n",
        "%pip install --upgrade transformers\n",
        "\n",
        "\n",
        "# 6. Training Arguments and Trainer Setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./outputs',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy'\n",
        "    \n",
        ")\n",
        "\n",
        "# Define metric computation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    acc = (preds == labels).mean()\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "def clean_collate_fn(batch):\n",
        "    # 只保留模型需要的欄位\n",
        "    valid_keys = {\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"}\n",
        "    collated = {}\n",
        "    for key in valid_keys:\n",
        "        if key in batch[0]:\n",
        "            collated[key] = torch.stack([item[key] for item in batch])\n",
        "    return collated\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=clean_collate_fn  \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='5712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   2/5712 : < :, Epoch 0.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 7. Train and Evaluate\n",
        "if __name__ == '__main__':\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"Test Accuracy: {metrics['eval_accuracy']:.4f}\")\n",
        "\n",
        "# 8. Save Model and Label Mappings\n",
        "    model.merge_and_unload()\n",
        "    os.makedirs('./saved_model', exist_ok=True)\n",
        "    model.save_pretrained('./saved_model')\n",
        "    tokenizer.save_pretrained('./saved_model')\n",
        "    with open('./saved_model/label2id.json', 'w') as f:\n",
        "        json.dump(label2id, f)\n",
        "    with open('./saved_model/id2label.json', 'w') as f:\n",
        "        json.dump(id2label, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzmf8LAmMDra",
        "outputId": "e34da672-6729-4fa1-e355-d87809a91695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: test_math.png\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'test_math.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Usage examples\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# 1. Train and save\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m#train()\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m#save_model()\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# 2. Test with an example image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[43mtest_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_math.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     test = \u001b[33m\"\u001b[39m\u001b[33m根據經濟部水利署的統計，截至2019年底，臺灣40座主要水庫中，淤積率超過30\u001b[39m\u001b[33m%\u001b[39m\u001b[33m的共有15座，例如霧社水庫淤積率達74.8\u001b[39m\u001b[33m%\u001b[39m\u001b[33m、烏山頭水庫達49.2\u001b[39m\u001b[33m%\u001b[39m\u001b[33m。顯示臺灣水庫淤積程度嚴重，影響水庫蓄水功能。下列何項策略最能有效改善上述現象\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m     test_text(test)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtest_image\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_image\u001b[39m(image_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing:\u001b[39m\u001b[33m\"\u001b[39m, image_path)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     text = \u001b[43mocr_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOCR Result:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, text)\n\u001b[32m     35\u001b[39m     tokenizer, model = load_classifier()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mocr_to_text\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mocr_to_text\u001b[39m(image_path: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Using pytesseract\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     text = pytesseract.image_to_string(img, lang=\u001b[33m'\u001b[39m\u001b[33meng\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text.strip()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/DL_final/.venv/lib/python3.12/site-packages/PIL/Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'test_math.png'"
          ]
        }
      ],
      "source": [
        "# 9. Inference Pipeline\n",
        "def ocr_to_text(image_path: str) -> str:\n",
        "    # Using pytesseract\n",
        "    img = Image.open(image_path)\n",
        "    text = pytesseract.image_to_string(img, lang='eng')\n",
        "    return text.strip()\n",
        "    # Or using EasyOCR:\n",
        "    # reader = easyocr.Reader(['en'])\n",
        "    # result = reader.readtext(image_path, detail=0)\n",
        "    # return ' '.join(result)\n",
        "\n",
        "\n",
        "def load_classifier(model_dir: str = './saved_model'):\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_dir)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def predict_text(text: str, tokenizer, model):\n",
        "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = logits.argmax(dim=-1).item()\n",
        "    label = id2label[pred_id]\n",
        "    subject, chapter = label.split('::')\n",
        "    return subject, chapter\n",
        "\n",
        "\n",
        "def test_image(image_path: str):\n",
        "    print(\"Processing:\", image_path)\n",
        "    text = ocr_to_text(image_path)\n",
        "    print(\"OCR Result:\\n\", text)\n",
        "    tokenizer, model = load_classifier()\n",
        "    subject, chapter_name = predict_text(text, tokenizer, model)\n",
        "    print(f\"Predicted Subject: {subject}\\nPredicted Chapter: {chapter_name}\")\n",
        "\n",
        "def test_text(text):\n",
        "    tokenizer, model = load_classifier()\n",
        "    subject, chapter_name = predict_text(text, tokenizer, model)\n",
        "    print(f\"Predicted Subject: {subject}\\nPredicted Chapter: {chapter_name}\")\n",
        "\n",
        "# Usage examples\n",
        "if __name__ == '__main__':\n",
        "    # 1. Train and save\n",
        "    #train()\n",
        "    #save_model()\n",
        "\n",
        "    # 2. Test with an example image\n",
        "    test_image('test_math.png')\n",
        "\n",
        "    test = \"根據經濟部水利署的統計，截至2019年底，臺灣40座主要水庫中，淤積率超過30%的共有15座，例如霧社水庫淤積率達74.8%、烏山頭水庫達49.2%。顯示臺灣水庫淤積程度嚴重，影響水庫蓄水功能。下列何項策略最能有效改善上述現象\"\n",
        "    test_text(test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-6V-gTSRE7"
      },
      "source": [
        "## textCNN pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WrTQl50XSoiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizerFast\n",
        "import json\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WipQyw_uSeB3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1904/1904 [01:12<00:00, 26.14it/s]\n",
            "Train: 100%|██████████| 1904/1904 [01:12<00:00, 26.14it/s]\n",
            "Eval: 100%|██████████| 106/106 [00:05<00:00, 20.31it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 | Train Loss: 1.9435, Acc: 0.4293 | Val Loss: 1.2461, Acc: 0.6250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1904/1904 [00:53<00:00, 35.88it/s]\n",
            "Train: 100%|██████████| 1904/1904 [00:53<00:00, 35.88it/s]\n",
            "Eval: 100%|██████████| 106/106 [00:02<00:00, 35.96it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5 | Train Loss: 1.3654, Acc: 0.5841 | Val Loss: 1.0608, Acc: 0.6678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1904/1904 [00:53<00:00, 35.46it/s]\n",
            "Train: 100%|██████████| 1904/1904 [00:53<00:00, 35.46it/s]\n",
            "Eval: 100%|██████████| 106/106 [00:02<00:00, 36.35it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5 | Train Loss: 1.1951, Acc: 0.6335 | Val Loss: 1.0054, Acc: 0.6838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1904/1904 [01:08<00:00, 27.84it/s]\n",
            "Train: 100%|██████████| 1904/1904 [01:08<00:00, 27.84it/s]\n",
            "Eval: 100%|██████████| 106/106 [00:03<00:00, 30.65it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5 | Train Loss: 1.0878, Acc: 0.6629 | Val Loss: 0.9571, Acc: 0.7004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 1904/1904 [00:50<00:00, 37.99it/s]\n",
            "Train: 100%|██████████| 1904/1904 [00:50<00:00, 37.99it/s]\n",
            "Eval: 100%|██████████| 106/106 [00:02<00:00, 36.55it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5 | Train Loss: 1.0200, Acc: 0.6804 | Val Loss: 0.9266, Acc: 0.7069\n",
            "Best TextCNN Val Acc: 0.7069\n",
            "DoRA-TextCNN initialized with 4087830 parameters\n",
            "Device: mps\n"
          ]
        }
      ],
      "source": [
        "# 3. TextCNN Model Definition\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim,\n",
        "                      out_channels=num_filters,\n",
        "                      kernel_size=k)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        x = self.embedding(input_ids)  # [B, L, D]\n",
        "        x = x.permute(0, 2, 1)        # [B, D, L]\n",
        "        convs = [torch.relu(conv(x)) for conv in self.convs]  # list of [B, F, L-k+1]\n",
        "        pools = [torch.max(c, dim=2)[0] for c in convs]     # list of [B, F]\n",
        "        out = torch.cat(pools, dim=1)                       # [B, F*len]\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out)\n",
        "\n",
        "# 4. Training and Evaluation Functions\n",
        "# 4. Tokenization and Dataset Definition\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
        "model_cnn = TextCNN(vocab_size=len(tokenizer), embed_dim=128,\n",
        "                    num_classes=len(label2id)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=1e-3)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoaders for TextCNN training\n",
        "class TextCNNDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        inputs = self.tokenizer(text, padding='max_length', truncation=True, \n",
        "                               max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset_cnn = TextCNNDataset(train_df['ques_detl'].tolist(), train_df['label'].tolist(), tokenizer)\n",
        "test_dataset_cnn = TextCNNDataset(test_df['ques_detl'].tolist(), test_df['label'].tolist(), tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset_cnn, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset_cnn, batch_size=32, shuffle=False)\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    for batch in tqdm(loader, desc='Train'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Eval'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "# 5. Run Training and Compare\n",
        "epochs = 5\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch(model_cnn, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = eval_epoch(model_cnn, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model_cnn.state_dict(), 'best_textcnn.pt')\n",
        "\n",
        "print(f\"Best TextCNN Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "# 6. Save Mappings for CNN\n",
        "with open('tokenizer_vocab.json', 'w') as f:\n",
        "    json.dump(tokenizer.vocab, f)\n",
        "with open('label2id.json', 'w') as f:\n",
        "    json.dump(label2id, f)\n",
        "\n",
        "# DoRA-Enhanced TextCNN Pipeline\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# DoRA-Enhanced TextCNN Model\n",
        "class DoRATextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
        "        super().__init__()\n",
        "        # Base embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim, out_channels=num_filters, kernel_size=k)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        # DoRA-inspired domain adaptation layers\n",
        "        self.domain_adapters = nn.ModuleList([\n",
        "            nn.Linear(num_filters, num_filters // 4)  # Low-rank adaptation\n",
        "            for _ in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        self.domain_scalers = nn.ModuleList([\n",
        "            nn.Linear(num_filters // 4, num_filters)  # Scale back up\n",
        "            for _ in kernel_sizes\n",
        "        ])\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
        "        \n",
        "        # Initialize domain adaptation weights\n",
        "        for adapter in self.domain_adapters:\n",
        "            nn.init.xavier_uniform_(adapter.weight)\n",
        "        for scaler in self.domain_scalers:\n",
        "            nn.init.xavier_uniform_(scaler.weight)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        x = self.embedding(input_ids)  # [B, L, D]\n",
        "        x = x.permute(0, 2, 1)        # [B, D, L]\n",
        "        \n",
        "        conv_outputs = []\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            conv_out = torch.relu(conv(x))  # [B, F, L-k+1]\n",
        "            \n",
        "            # Apply DoRA-style domain adaptation\n",
        "            pooled = torch.max(conv_out, dim=2)[0]  # [B, F]\n",
        "            adapted = self.domain_adapters[i](pooled)  # [B, F//4]\n",
        "            scaled = self.domain_scalers[i](adapted)   # [B, F]\n",
        "            \n",
        "            # Residual connection with original pooled features\n",
        "            enhanced = pooled + scaled\n",
        "            conv_outputs.append(enhanced)\n",
        "        \n",
        "        out = torch.cat(conv_outputs, dim=1)  # [B, F*len]\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out)\n",
        "\n",
        "# Initialize DoRA-enhanced model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
        "model_dora_cnn = DoRATextCNN(\n",
        "    vocab_size=len(tokenizer), \n",
        "    embed_dim=128,\n",
        "    num_classes=len(label2id)\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_dora_cnn.parameters(), lr=1e-3)\n",
        "\n",
        "print(f\"DoRA-TextCNN initialized with {sum(p.numel() for p in model_dora_cnn.parameters())} parameters\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DoRA Training Functions\n",
        "def train_epoch_dora(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    for batch in tqdm(loader, desc='DoRA Train'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "    \n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "def eval_epoch_dora(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='DoRA Eval'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            outputs = model(input_ids)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "    \n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "# Training Loop for DoRA-TextCNN\n",
        "print(\"\\n=== Training DoRA-Enhanced TextCNN ===\")\n",
        "epochs = 5\n",
        "best_dora_acc = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch_dora(model_dora_cnn, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = eval_epoch_dora(model_dora_cnn, test_loader, criterion)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "    \n",
        "    if val_acc > best_dora_acc:\n",
        "        best_dora_acc = val_acc\n",
        "        torch.save(model_dora_cnn.state_dict(), 'best_dora_textcnn.pt')\n",
        "        print(f\"  → New best model saved! Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "print(f\"\\nBest DoRA-TextCNN Val Acc: {best_dora_acc:.4f}\")\n",
        "\n",
        "# Save DoRA model mappings\n",
        "with open('dora_tokenizer_vocab.json', 'w') as f:\n",
        "    json.dump(tokenizer.vocab, f)\n",
        "with open('dora_label2id.json', 'w') as f:\n",
        "    json.dump(label2id, f)\n",
        "\n",
        "print(\"DoRA-TextCNN training completed and model saved!\")\n",
        "\n",
        "# Print model comparison summary\n",
        "print(\"\\n=== Model Architecture Summary ===\")\n",
        "print(f\"DoRA-TextCNN Parameters: {sum(p.numel() for p in model_dora_cnn.parameters()):,}\")\n",
        "print(f\"Domain Adaptation Layers: {len(model_dora_cnn.domain_adapters)}\")\n",
        "print(f\"Low-rank dimension: {model_dora_cnn.domain_adapters[0].out_features}\")\n",
        "print(f\"Full feature dimension: {model_dora_cnn.domain_scalers[0].out_features}\")\n",
        "print(f\"Compression ratio: {model_dora_cnn.domain_scalers[0].out_features / model_dora_cnn.domain_adapters[0].out_features:.1f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DoRA Inference Pipeline\n",
        "def load_dora_classifier(model_path='best_dora_textcnn.pt'):\n",
        "    \"\"\"\n",
        "    Load the trained DoRA-TextCNN model for inference\n",
        "    \"\"\"\n",
        "    model = DoRATextCNN(\n",
        "        vocab_size=len(tokenizer),\n",
        "        embed_dim=128,\n",
        "        num_classes=len(label2id)\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict_with_dora(text: str, model, tokenizer, top_k=3):\n",
        "    \"\"\"\n",
        "    Predict using DoRA-TextCNN model with confidence scores\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(text, padding='max_length', truncation=True, \n",
        "                      max_length=128, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        probs = torch.softmax(outputs, dim=-1)\n",
        "        top_probs, top_indices = torch.topk(probs, k=top_k, dim=-1)\n",
        "    \n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        idx = top_indices[0][i].item()\n",
        "        prob = top_probs[0][i].item()\n",
        "        label = id2label[idx]\n",
        "        subject, chapter = label.split('::')\n",
        "        results.append({\n",
        "            'subject': subject,\n",
        "            'chapter': chapter,\n",
        "            'confidence': prob\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "def test_dora_model(test_texts=None):\n",
        "    \"\"\"\n",
        "    Test the DoRA model with sample texts\n",
        "    \"\"\"\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            \"根據經濟部水利署的統計，截至2019年底，臺灣40座主要水庫中，淤積率超過30%的共有15座\",\n",
        "            \"求解二次方程式 x² + 5x + 6 = 0 的解\",\n",
        "            \"什麼是三角函數的基本性質？\"\n",
        "        ]\n",
        "    \n",
        "    print(\"\\n=== DoRA Model Inference Testing ===\")\n",
        "    model = load_dora_classifier()\n",
        "    \n",
        "    for i, text in enumerate(test_texts, 1):\n",
        "        print(f\"\\nTest {i}: {text[:50]}...\")\n",
        "        results = predict_with_dora(text, model, tokenizer, top_k=3)\n",
        "        \n",
        "        for j, result in enumerate(results, 1):\n",
        "            print(f\"  {j}. {result['subject']} - {result['chapter']} \"\n",
        "                  f\"(Confidence: {result['confidence']:.3f})\")\n",
        "\n",
        "# Run the test\n",
        "if __name__ == '__main__':\n",
        "    test_dora_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
