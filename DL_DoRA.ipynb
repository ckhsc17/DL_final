{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1PP8GhTDoxg"
      },
      "source": [
        "## Packages import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2SLtTNCSOgO8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRtlybIfA8bQ",
        "outputId": "ce60812f-0e5b-4740-8b53-9a487dc7c2d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(2152) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in ./.venv/lib/python3.12/site-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(2153) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%pip install pytesseract pandas scikit-learn transformers json\n",
        "%pip install torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Optional OCR tools\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "# or use EasyOCR:\n",
        "# import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVj1O-69EN49",
        "outputId": "4a5bf68e-07d6-4779-edba-cd515ea2c0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用 Apple M1 GPU (MPS)\n"
          ]
        }
      ],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "\n",
        "# Step 1: 自動選擇 device\n",
        "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"使用 Apple M1 GPU (MPS)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"使用 CPU（找不到 MPS）\")\n",
        "# # Check GPU\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device('mps')\n",
        "#     print(f'使用 GPU：{torch.cuda.get_device_name(0)}')\n",
        "# else:\n",
        "#     device = torch.device('cpu')\n",
        "#     print('使用 CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kztd1CKCXI"
      },
      "source": [
        "## Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "SZcnhYfIESMv",
        "outputId": "a1753eb7-1368-40c1-b911-863bfa1e6aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question Bank Columns: ['subject', 'ques_no', 'chapter_name', 'section_name', 'ques_detl']\n",
            "Chapter List Columns: ['year_grade', 'book', 'chapter_num', 'chapter_name', 'section_num', 'section_name']\n",
            "Question Bank Columns: ['subject', 'ques_no', 'chapter_name', 'section_name', 'ques_detl']\n",
            "Chapter List Columns: ['year_grade', 'book', 'chapter_num', 'chapter_name', 'section_num', 'section_name']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>ques_no</th>\n",
              "      <th>chapter_name_x</th>\n",
              "      <th>section_name</th>\n",
              "      <th>ques_detl</th>\n",
              "      <th>year_grade</th>\n",
              "      <th>book</th>\n",
              "      <th>chapter_num</th>\n",
              "      <th>chapter_name_y</th>\n",
              "      <th>section_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810001</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810002</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\u000b(A)－25　(B...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810003</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\u000b(A)－8　(B...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810004</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math</td>\n",
              "      <td>2MA0810005</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果＋40°表示北緯40°，則南緯30°該如何表示？\u000b(A)30°　(B)－30°  (C)...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject     ques_no chapter_name_x section_name  \\\n",
              "0    math  2MA0810001          整數的運算        負數與數線   \n",
              "1    math  2MA0810002          整數的運算        負數與數線   \n",
              "2    math  2MA0810003          整數的運算        負數與數線   \n",
              "3    math  2MA0810004          整數的運算        負數與數線   \n",
              "4    math  2MA0810005          整數的運算        負數與數線   \n",
              "\n",
              "                                           ques_detl  year_grade  book  \\\n",
              "0  以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...         8.0   1.0   \n",
              "1  若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\n",
              "(A)－25　(B...         8.0   1.0   \n",
              "2  如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\n",
              "(A)－8　(B...         8.0   1.0   \n",
              "3  如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...         8.0   1.0   \n",
              "4  如果＋40°表示北緯40°，則南緯30°該如何表示？\n",
              "(A)30°　(B)－30°  (C)...         8.0   1.0   \n",
              "\n",
              "   chapter_num chapter_name_y  section_num  \n",
              "0          1.0          整數的運算          1.0  \n",
              "1          1.0          整數的運算          1.0  \n",
              "2          1.0          整數的運算          1.0  \n",
              "3          1.0          整數的運算          1.0  \n",
              "4          1.0          整數的運算          1.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_and_merge(subject: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load question bank and chapter list CSVs for a given subject from Database/{subject}_Database and merge on chapter ID.\n",
        "\n",
        "    Args:\n",
        "        subject: 'math' or 'social'\n",
        "    Returns:\n",
        "        DataFrame with columns: question_text, chapter_name, subject\n",
        "    \"\"\"\n",
        "    base_path = f\"Database/{subject}_Database\"\n",
        "    qbank_path = f\"{base_path}/{subject}_question_bank.csv\"\n",
        "    chap_path = f\"{base_path}/{subject}_chapter_list.csv\"\n",
        "    \n",
        "    qdf = pd.read_csv(qbank_path)\n",
        "    cdf = pd.read_csv(chap_path)\n",
        "    qdf.columns = qdf.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "    cdf.columns = cdf.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "    print(\"Question Bank Columns:\", qdf.columns.tolist())\n",
        "    print(\"Chapter List Columns:\", cdf.columns.tolist())\n",
        "\n",
        "\n",
        "    df = qdf.merge(cdf, on='section_name', how='left')\n",
        "    df['subject'] = subject\n",
        "    return df\n",
        "\n",
        "# Load and combine data from correct paths\n",
        "df = pd.concat([load_and_merge('math'), load_and_merge('social')], ignore_index=True)\n",
        "\n",
        "df.count()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C2K-oAKnKlbY",
        "outputId": "5f522948-22c6-44df-f8c7-e30c60ff1d96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>chapter_name_x</th>\n",
              "      <th>section_name</th>\n",
              "      <th>ques_detl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\u000b(A)－25　(B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\u000b(A)－8　(B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math</td>\n",
              "      <td>整數的運算</td>\n",
              "      <td>負數與數線</td>\n",
              "      <td>如果＋40°表示北緯40°，則南緯30°該如何表示？\u000b(A)30°　(B)－30°  (C)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject chapter_name_x section_name  \\\n",
              "0    math          整數的運算        負數與數線   \n",
              "1    math          整數的運算        負數與數線   \n",
              "2    math          整數的運算        負數與數線   \n",
              "3    math          整數的運算        負數與數線   \n",
              "4    math          整數的運算        負數與數線   \n",
              "\n",
              "                                           ques_detl  \n",
              "0  以中午12時為基準，下午3時記作＋3，那麼上午10時可以記作多少？(A)＋10(B)－10(...  \n",
              "1  若數學科成績以30分為基準，得40分記作＋10，那麼考25分可記作多少？\n",
              "(A)－25　(B...  \n",
              "2  如果以正午12時為基準，當日下午4時用＋4表示，則當日上午8時應記為多少？\n",
              "(A)－8　(B...  \n",
              "3  如果以中午12時為基準，當日下午2時記為＋8，則當日上午6時應記為多少？(A)－24(B)－...  \n",
              "4  如果＋40°表示北緯40°，則南緯30°該如何表示？\n",
              "(A)30°　(B)－30°  (C)...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[['subject','chapter_name_x','section_name','ques_detl']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ZMGU1kj-JjuO",
        "outputId": "7c6712f6-2d21-4664-a003-a55d72f32182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subject           33839\n",
              "chapter_name_x    33839\n",
              "section_name      33839\n",
              "ques_detl         33839\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU818S_rJ9-Y",
        "outputId": "f1bfdda4-0286-47e4-eec6-e3493defcc64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33839"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kpzeLe4RKJzZ"
      },
      "outputs": [],
      "source": [
        "# 2. Label Encoding\n",
        "# Combine subject and chapter_name as classification label\n",
        "\n",
        "df['label_str'] = df['subject'] + '::' + df['chapter_name_x']\n",
        "label2id = {lab: i for i, lab in enumerate(sorted(df['label_str'].unique()))}\n",
        "id2label = {i: lab for lab, i in label2id.items()}\n",
        "df['label'] = df['label_str'].map(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_y24qatKGl8",
        "outputId": "a6fe1e40-f33d-421f-80f3-6f3e4043c336"
      },
      "outputs": [],
      "source": [
        "# 3. Train/Test Split\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
        "\n",
        "# 4. Tokenization and Dataset Definition\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class QDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        inputs = self.tokenizer(text,\n",
        "                                 padding='max_length',\n",
        "                                 truncation=True,\n",
        "                                 max_length=self.max_len,\n",
        "                                 return_tensors='pt')\n",
        "        item = {k: v.squeeze() for k, v in inputs.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_dataset = QDataset(train_df['ques_detl'].tolist(), train_df['label'].tolist(), tokenizer)\n",
        "test_dataset = QDataset(test_df['ques_detl'].tolist(), test_df['label'].tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpJoDYM7Lebd",
        "outputId": "d34f857f-3242-4519-cae9-48451c141bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(2171) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pytorch \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[23 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
            "  \u001b[31m   \u001b[0m     main()\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
            "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
            "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 280, in build_wheel\n",
            "  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/pip-build-env-8_hmy26c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 435, in build_wheel\n",
            "  \u001b[31m   \u001b[0m     return _build(['bdist_wheel', '--dist-info-dir', str(metadata_directory)])\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/pip-build-env-8_hmy26c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 423, in _build\n",
            "  \u001b[31m   \u001b[0m     return self._build_with_temp_dir(\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/pip-build-env-8_hmy26c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 404, in _build_with_temp_dir\n",
            "  \u001b[31m   \u001b[0m     self.run_setup()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/pip-build-env-8_hmy26c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 512, in run_setup\n",
            "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/pip-build-env-8_hmy26c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
            "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 15, in <module>\n",
            "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pytorch\n",
            "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(2193) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.32.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.5.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.8.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python(2246) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/var/folders/1v/tq021spn1sz10p3_782b7sb80000gp/T/ipykernel_97906/2043180508.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch\n",
        "%pip install -U accelerate\n",
        "%pip install -U transformers\n",
        "\n",
        "\n",
        "# 5. Model Initialization\n",
        "n_labels = len(label2id)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=n_labels)\n",
        "\n",
        "# 6. Training Arguments and Trainer Setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./outputs',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy'\n",
        ")\n",
        "\n",
        "# Define metric computation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    acc = (preds == labels).mean()\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Dascupt/DL_final/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='5712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  13/5712 02:11 < 18:53:10, 0.08 it/s, Epoch 0.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 7. Train and Evaluate\n",
        "if __name__ == '__main__':\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"Test Accuracy: {metrics['eval_accuracy']:.4f}\")\n",
        "\n",
        "# 8. Save Model and Label Mappings\n",
        "os.makedirs('./saved_model', exist_ok=True)\n",
        "model.save_pretrained('./saved_model')\n",
        "tokenizer.save_pretrained('./saved_model')\n",
        "with open('./saved_model/label2id.json', 'w') as f:\n",
        "    json.dump(label2id, f)\n",
        "with open('./saved_model/id2label.json', 'w') as f:\n",
        "    json.dump(id2label, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gTQ7LEJPbMa"
      },
      "outputs": [],
      "source": [
        "# 7. Train and Evaluate\n",
        "def train():\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"Test Accuracy: {metrics['eval_accuracy']:.4f}\")\n",
        "\n",
        "# 8. Save Model and Label Mappings\n",
        "def save_model():\n",
        "    os.makedirs('./saved_model', exist_ok=True)\n",
        "    model.save_pretrained('./saved_model')\n",
        "    tokenizer.save_pretrained('./saved_model')\n",
        "    with open('./saved_model/label2id.json', 'w') as f:\n",
        "        json.dump(label2id, f)\n",
        "    with open('./saved_model/id2label.json', 'w') as f:\n",
        "        json.dump(id2label, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzmf8LAmMDra",
        "outputId": "e34da672-6729-4fa1-e355-d87809a91695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: test_math.png\n",
            "OCR Result:\n",
            " NU E#m \"To, Aga 120 tal -\n",
            "gee $5 RANA BA REF AR\n",
            "\n",
            ", eT o +s an ARH A AG > PLT 66\n",
            "CPE rC a) KALI S 2 SRA?\n",
            "\n",
            "  \n",
            "\n",
            "¢ C\n",
            "Predicted Subject: math\n",
            "Predicted Chapter: 相似形\n",
            "Predicted Subject: social\n",
            "Predicted Chapter: 地理：基本概念與臺灣\n"
          ]
        }
      ],
      "source": [
        "# 9. Inference Pipeline\n",
        "def ocr_to_text(image_path: str) -> str:\n",
        "    # Using pytesseract\n",
        "    img = Image.open(image_path)\n",
        "    text = pytesseract.image_to_string(img, lang='eng')\n",
        "    return text.strip()\n",
        "    # Or using EasyOCR:\n",
        "    # reader = easyocr.Reader(['en'])\n",
        "    # result = reader.readtext(image_path, detail=0)\n",
        "    # return ' '.join(result)\n",
        "\n",
        "\n",
        "def load_classifier(model_dir: str = './saved_model'):\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_dir)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def predict_text(text: str, tokenizer, model):\n",
        "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = logits.argmax(dim=-1).item()\n",
        "    label = id2label[pred_id]\n",
        "    subject, chapter = label.split('::')\n",
        "    return subject, chapter\n",
        "\n",
        "\n",
        "def test_image(image_path: str):\n",
        "    print(\"Processing:\", image_path)\n",
        "    text = ocr_to_text(image_path)\n",
        "    print(\"OCR Result:\\n\", text)\n",
        "    tokenizer, model = load_classifier()\n",
        "    subject, chapter_name = predict_text(text, tokenizer, model)\n",
        "    print(f\"Predicted Subject: {subject}\\nPredicted Chapter: {chapter_name}\")\n",
        "\n",
        "def test_text(text):\n",
        "    tokenizer, model = load_classifier()\n",
        "    subject, chapter_name = predict_text(text, tokenizer, model)\n",
        "    print(f\"Predicted Subject: {subject}\\nPredicted Chapter: {chapter_name}\")\n",
        "\n",
        "# Usage examples\n",
        "if __name__ == '__main__':\n",
        "    # 1. Train and save\n",
        "    #train()\n",
        "    #save_model()\n",
        "\n",
        "    # 2. Test with an example image\n",
        "    test_image('test_math.png')\n",
        "\n",
        "    test = \"根據經濟部水利署的統計，截至2019年底，臺灣40座主要水庫中，淤積率超過30%的共有15座，例如霧社水庫淤積率達74.8%、烏山頭水庫達49.2%。顯示臺灣水庫淤積程度嚴重，影響水庫蓄水功能。下列何項策略最能有效改善上述現象\"\n",
        "    test_text(test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-6V-gTSRE7"
      },
      "source": [
        "## textCNN pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrTQl50XSoiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizerFast\n",
        "import json\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WipQyw_uSeB3"
      },
      "outputs": [],
      "source": [
        "# 3. TextCNN Model Definition\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[3,4,5], num_filters=100):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim,\n",
        "                      out_channels=num_filters,\n",
        "                      kernel_size=k)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        x = self.embedding(input_ids)  # [B, L, D]\n",
        "        x = x.permute(0, 2, 1)        # [B, D, L]\n",
        "        convs = [torch.relu(conv(x)) for conv in self.convs]  # list of [B, F, L-k+1]\n",
        "        pools = [torch.max(c, dim=2)[0] for c in convs]     # list of [B, F]\n",
        "        out = torch.cat(pools, dim=1)                       # [B, F*len]\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out)\n",
        "\n",
        "# 4. Training and Evaluation Functions\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_cnn = TextCNN(vocab_size=len(tokenizer), embed_dim=128,\n",
        "                    num_classes=len(label2id)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=1e-3)\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    for batch in tqdm(loader, desc='Train'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Eval'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "# 5. Run Training and Compare\n",
        "epochs = 5\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch(model_cnn, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = eval_epoch(model_cnn, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model_cnn.state_dict(), 'best_textcnn.pt')\n",
        "\n",
        "print(f\"Best TextCNN Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "# 6. Save Mappings for CNN\n",
        "with open('tokenizer_vocab.json', 'w') as f:\n",
        "    json.dump(tokenizer.vocab, f)\n",
        "with open('label2id.json', 'w') as f:\n",
        "    json.dump(label2id, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
